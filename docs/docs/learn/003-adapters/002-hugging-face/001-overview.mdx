---
sidebar_label: 'Overview'
---

# Hugging Face Adapter

Hugging Face is a popular platform for hosting and accessing machine learning models, particularly natural language
processing (NLP) models. It provides a unified interface and inference API to interact with many state-of-the-art NLP
models like Mistral, LLAMA3, and more.

Hugging Face is a great fit for `NLUX` because it allows easy integration with top large language models without needing
to host and serve the models yourself. `NLUX` provides an adapter specifically for Hugging Face to enable using those
models with just a few lines of configuration.

## Supported Features

The current version of `NLUX` provides support for [conversational tasks](https://huggingface.co/tasks/conversational)
using Hugging Face's [Inference API](https://huggingface.co/docs/api-inference/index).

This would allow you to do things like:

* **Host your own conversational AI model** on Hugging Face and use it with `NLUX`.
* **Use any pre-trained conversational model** from Hugging Face with
`NLUX` ([over 2000 models are available](https://huggingface.co/models?pipeline_tag=conversational)).
* **Customize the model**'s responses to fit your use case, using system messages, custom prompts, and more.
* **Stream conversations** to the users in real-time, as they're generated by the model.

## API Documentation

You can refer to the [API documentation](/reference/adapters/hugging-face) for more details on how to use the Hugging Face
adapter, and the configuration options available.
