import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## How to connect to Llama on Hugging Face

### Installation

<Tabs groupId="package" queryString>
    <TabItem value="npm" label="NPM">
        ```bash
        npm install @nlux/hf
        ```
    </TabItem>
    <TabItem value="yarn" label="Yarn">
        ```bash
        yarn add @nlux/hf
        ```
    </TabItem>
    <TabItem value="pnpm" label="PNPM">
        ```bash
        pnpm add @nlux/hf
        ```
    </TabItem>
</Tabs>

### Usage

```tsx
import {
    createAdapter,
    llama2InputPreProcessor,
    llama2OutputPreProcessor,
} from '@nlux/hf';

const adapter = createAdapter()
    .dataTransferMode('stream')
    .withModel('<HUGGING FACE MODEL NAME>')
    .withMaxNewTokens(800)
    .withInputPreProcessor(llama2InputPreProcessor)
    .withOutputPostProcessor(llama2OutputPreProcessor);

const aiChat = createAiChat().withAdapter(adapter);
aiChat.mount(rootElement);
```
